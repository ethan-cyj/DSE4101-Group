{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETHUSD Minute Data\n",
    "- Resampling into Daily Data\n",
    "- Daily RV\n",
    "- daily returns (pct change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the BTC/USD dataset\n",
    "file_path =  \"../../data/raw/minute/ethusd.csv\"\n",
    "\n",
    "save_path = \"../../data/processed/minute/ethusd.csv\"\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert Unix Timestamp (milliseconds) to datetime\n",
    "data['time'] = pd.to_datetime(data['time'], unit='ms')\n",
    "data.set_index('time', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "# Calculate intraday returns (log returns)\n",
    "data['Log Return'] = np.log(data['close'] / data['close'].shift(1))\n",
    "# Remove rows with NaN returns (due to the shift operation)\n",
    "data.dropna(subset=['Log Return'], inplace=True)\n",
    "\n",
    "# Calculate realized variance\n",
    "rv_1d = data.resample('1D')['Log Return'].apply(lambda x: np.sum(x**2))\n",
    "\n",
    "\n",
    "drop_columns = ['Log Return']\n",
    "data.drop(columns=drop_columns, inplace=True)\n",
    "daily_data = data.resample('1D').agg({\n",
    "    'open': 'first',        # First open price of the day\n",
    "    'close': 'last',        # Last close price of the day\n",
    "    'high': 'max',          # Highest price of the day\n",
    "    'low': 'min',           # Lowest price of the day\n",
    "    'volume': 'sum',        # Total volume for the day\n",
    "})\n",
    "daily_data['1D RV'] = rv_1d\n",
    "\n",
    "# Drop any rows with NaN values (e.g., incomplete days)\n",
    "daily_data.dropna(subset=['open', 'close', 'high', 'low', 'volume', '1D RV'], inplace=True)\n",
    "# Calculate daily returns from the daily close price\n",
    "daily_data['daily_return'] = daily_data['close'].pct_change()\n",
    "#rename columns\n",
    "daily_data.rename(columns={'1D RV': 'realized_variance'}, inplace=True)\n",
    "daily_data.head()\n",
    "daily_data.to_csv(\"../../data/ethusd_group_project.csv\", index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parkinson(data, window):\n",
    "    \"\"\"\n",
    "    Calculate Parkinson Volatility using high and low prices over a rolling window.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame with 'High' and 'Low' columns.\n",
    "    - window: Rolling window size for Parkinson Volatility (e.g., 7 or 30 days).\n",
    "    \n",
    "    Returns:\n",
    "    - Series containing Parkinson Volatility values.\n",
    "    \"\"\"\n",
    "    parkinson_vol = np.sqrt(\n",
    "        (1 / (4 * np.log(2) * window)) *\n",
    "        (np.log(data['High'] / data['Low']) ** 2).rolling(window=window).sum()\n",
    "    )\n",
    "    return parkinson_vol\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
